{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "import gc\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "genres = 'classical jazz metal pop rock'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('inferno')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for g in genres:\n",
    "    pathlib.Path(f'dataset/img_data/{g}').mkdir(parents=True, exist_ok=True)     \n",
    "    for filename in os.listdir(f'./dataset/genres/{g}'):\n",
    "        songname = f'./dataset/genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        plt.savefig(f'dataset/img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "        plt.clf()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(filename,name):\n",
    "    plt.interactive(False)\n",
    "    clip, sample_rate = librosa.load(filename, sr=None)\n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    filename  = 'working/train/' + name + '.jpg'\n",
    "    plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del filename,name,clip,sample_rate,fig,ax,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram_test(filename,name):\n",
    "    plt.interactive(False)\n",
    "    clip, sample_rate = librosa.load(filename, sr=None)\n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    filename  = Path('working/test/' + name + '.jpg')\n",
    "    fig.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del filename,name,clip,sample_rate,fig,ax,S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = open('./dataset/data.csv', 'w', newline='')\n",
    "header = [\"id\",\"class\"]\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "for g in genres:\n",
    "    for filename in os.listdir(f'./dataset/genres/{g}'):\n",
    "        songname = f'./dataset/genres/{g}/{filename}'\n",
    "        create_spectrogram(songname,filename)\n",
    "        \n",
    "        # extracts the  genre name\n",
    "        labels.append(filename.split('.')[0])\n",
    "        ids.append(filename + '.jpg')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'ID': ids, 'Class': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classical.00046.au.jpg</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classical.00094.au.jpg</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>classical.00030.au.jpg</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>classical.00005.au.jpg</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>classical.00010.au.jpg</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID      Class\n",
       "0  classical.00046.au.jpg  classical\n",
       "1  classical.00094.au.jpg  classical\n",
       "2  classical.00030.au.jpg  classical\n",
       "3  classical.00005.au.jpg  classical\n",
       "4  classical.00010.au.jpg  classical"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.backend import placeholder\n",
    "from keras.layers import Conv2D, MaxPooling2D, InputLayer\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    validation_split=.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 375 images belonging to 5 classes.\n",
      "Found 125 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = df,\n",
    "    directory=\"working/train/\",\n",
    "    x_col = \"ID\",\n",
    "    y_col = \"Class\",\n",
    "    subset=\"training\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(128, 128)\n",
    ")\n",
    "\n",
    "valid_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = df,\n",
    "    directory=\"working/train/\",\n",
    "    x_col = \"ID\",\n",
    "    y_col = \"Class\",\n",
    "    subset=\"validation\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(128, 128)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 16,813,381\n",
      "Trainable params: 16,813,381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeremy/miniconda3/envs/cs4803-project/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "\n",
    "def get_model(weights=False):\n",
    "    vgg_model = applications.VGG16(weights='imagenet',\n",
    "                                   include_top=False,\n",
    "                                   input_shape=(128, 128, 3))\n",
    "\n",
    "    # Creating dictionary that maps layer names to the layers\n",
    "    layer_dict = dict([(layer.name, layer) for layer in vgg_model.layers])\n",
    "\n",
    "    # Getting output tensor of the last VGG layer that we want to include\n",
    "    x = vgg_model.output\n",
    "\n",
    "    # Stacking a new simple convolutional network on top of it    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(5, activation='softmax')(x)\n",
    "\n",
    "    # Creating new model. Please note that this is NOT a Sequential() model.\n",
    "    from keras.models import Model\n",
    "    custom_model = Model(input=vgg_model.input, output=x)\n",
    "    \n",
    "    if weights:\n",
    "        custom_model.load(weights)\n",
    "    \n",
    "    return custom_model\n",
    "\n",
    "\n",
    "# Do not forget to compile it\n",
    "custom_model = get_model()\n",
    "custom_model.compile(loss='categorical_crossentropy',\n",
    "                     optimizer='rmsprop',\n",
    "                     metrics=['accuracy'])\n",
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      " 7/11 [==================>...........] - ETA: 15s - loss: 11.0170 - acc: 0.2277"
     ]
    }
   ],
   "source": [
    "#Fitting keras model, no test gen for now\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "#STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "custom_model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=75\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.save('vgg_sound_classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SONG_PATH = \"working/train/classical.00000.au.jpg\"\n",
    "STYLE_SONG_PATH = \"working/train/jazz.00000.au.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_HEIGHT = 128\n",
    "TARGET_WIDTH = 128\n",
    "TARGET_SIZE = (TARGET_HEIGHT, TARGET_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cImage = load_img(path=SAMPLE_SONG_PATH, target_size=TARGET_SIZE)\n",
    "cImArr = img_to_array(cImage)\n",
    "cImArr = np.expand_dims(cImArr, axis=0)\n",
    "cImArr = K.variable(cImArr, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cImArr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sImage = load_img(path=SAMPLE_SONG_PATH, target_size=TARGET_SIZE)\n",
    "sImArr = img_to_array(sImage)\n",
    "sImArr = np.expand_dims(sImArr, axis=0)\n",
    "sImArr = K.variable(sImArr, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatedImage = np.random.randint(\n",
    "    256, size=(1, TARGET_WIDTH, TARGET_HEIGHT, 3)).astype('float64')\n",
    "generatedImagePlaceholder = K.placeholder(shape=(1, TARGET_WIDTH, TARGET_HEIGHT, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLayerIndexByName(model, layername):\n",
    "    for idx, layer in enumerate(model.layers):\n",
    "        if layer.name == layername:\n",
    "            return idx\n",
    "        \n",
    "def get_feature_reps(x, layer_names, model):\n",
    "    \"\"\"\n",
    "    Get feature representations of input x for one or more layers in a given model.\n",
    "    \"\"\"\n",
    "    featMatrices = []\n",
    "    inp = model.input\n",
    "    \n",
    "    outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "    functors = [K.function([inp, K.learning_phase()], [out]) for out in outputs]    # evaluation functions\n",
    "\n",
    "    # Testing\n",
    "    layer_outs = [func([x, 1.]) for func in functors]\n",
    "\n",
    "    for ln in layer_names:\n",
    "        i = getLayerIndexByName(model, ln)\n",
    "        featMatrices.append(layer_outs[i])\n",
    "        \n",
    "        \n",
    "    return featMatrices\n",
    "\n",
    "def get_content_loss(F, P):\n",
    "    cLoss = 0.5*K.sum(K.square(F - P))\n",
    "    return cLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Gram_matrix(F):\n",
    "    G = K.dot(F, K.transpose(F))\n",
    "    return G\n",
    "\n",
    "def get_style_loss(ws, Gs, As):\n",
    "    sLoss = K.variable(0.)\n",
    "    for w, G, A in zip(ws, Gs, As):\n",
    "        M_l = K.int_shape(G)[1]\n",
    "        N_l = K.int_shape(G)[0]\n",
    "        G_gram = get_Gram_matrix(G)\n",
    "        A_gram = get_Gram_matrix(A)\n",
    "        sLoss+= w*0.25*K.sum(K.square(G_gram - A_gram))/ (N_l**2 * M_l**2)\n",
    "    return sLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_loss(gImPlaceholder, alpha=1.0, beta=10000.0):\n",
    "    F = get_feature_reps(gImPlaceholder, layer_names=[cLayerName], model=gModel)[0]\n",
    "    Gs = get_feature_reps(gImPlaceholder, layer_names=sLayerNames, model=gModel)\n",
    "    contentLoss = get_content_loss(F, P)\n",
    "    styleLoss = get_style_loss(ws, Gs, As)\n",
    "    totalLoss = alpha*contentLoss + beta*styleLoss\n",
    "    return totalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(gImArr):\n",
    "    \"\"\"\n",
    "    Calculate total loss using K.function\n",
    "    \"\"\"\n",
    "    if gImArr.shape != (1, TARGET_WIDTH, TARGET_WIDTH, 3):\n",
    "        gImArr = gImArr.reshape((1, TARGET_WIDTH, TARGET_HEIGHT, 3))\n",
    "    loss_fcn = K.function([gModel.input], [get_total_loss(gModel.input)])\n",
    "    return loss_fcn([gImArr])[0].astype('float64')\n",
    "\n",
    "def get_grad(gImArr):\n",
    "    \"\"\"\n",
    "    Calculate the gradient of the loss function with respect to the generated image\n",
    "    \"\"\"\n",
    "    if gImArr.shape != (1, TARGET_WIDTH, TARGET_WIDTH, 3):\n",
    "        gImArr = gImArr.reshape((1, TARGET_WIDTH, TARGET_HEIGHT, 3))\n",
    "    grad_fcn = K.function([gModel.input], \n",
    "                          K.gradients(get_total_loss(gModel.input), [gModel.input]))\n",
    "    grad = grad_fcn([gImArr])[0].flatten().astype('float64')\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Style Transfer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf_session = K.get_session()\n",
    "cModel = get_model()\n",
    "sModel = get_model()\n",
    "gModel = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cLayerName = 'conv2d_2'\n",
    "sLayerNames = [\n",
    "    'conv2d_1',\n",
    "    'conv2d_2',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "P = get_feature_reps(x=cImArr, layer_names=[cLayerName], model=cModel)[0]\n",
    "As = get_feature_reps(x=sImArr, layer_names=sLayerNames, model=sModel)\n",
    "ws = np.ones(len(sLayerNames)) / float(len(sLayerNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 100\n",
    "x_val = generatedImage.flatten()\n",
    "xopt, f_val, info= fmin_l_bfgs_b(calculate_loss, x_val, fprime=get_grad,\n",
    "                            maxiter=iterations, disp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xopt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xopt = xopt.reshape(128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.fromarray(xopt, 'RGB')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from scipy.optimize import fmin_l_bfgs_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_session = K.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cModel = VGG16(include_top=False, weights='imagenet', input_tensor=cImArr)\n",
    "sModel = VGG16(include_top=False, weights='imagenet', input_tensor=sImArr)\n",
    "gModel = VGG16(include_top=False, weights='imagenet', input_tensor=generatedImagePlaceholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cLayerName = 'block4_conv2'\n",
    "sLayerNames = [\n",
    "                'block1_conv1',\n",
    "                'block2_conv1',\n",
    "                'block3_conv1',\n",
    "                'block4_conv1',\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = get_feature_reps(x=cImArr, layer_names=[cLayerName], model=cModel)[0]\n",
    "As = get_feature_reps(x=sImArr, layer_names=sLayerNames, model=sModel)\n",
    "ws = np.ones(len(sLayerNames))/float(len(sLayerNames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterations = 4\n",
    "x_val = generatedImage.flatten()\n",
    "xopt, f_val, info= fmin_l_bfgs_b(calculate_loss, x_val, fprime=get_grad,\n",
    "                            maxiter=iterations, disp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xopt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xopt = xopt.reshape(128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.fromarray(xopt, 'RGB')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
