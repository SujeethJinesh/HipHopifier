{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "import gc\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('inferno')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "genres = 'classical jazz metal pop rock'.split()\n",
    "for g in genres:\n",
    "    pathlib.Path(f'dataset/img_data/{g}').mkdir(parents=True, exist_ok=True)     \n",
    "    for filename in os.listdir(f'./dataset/genres/{g}'):\n",
    "        songname = f'./dataset/genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        plt.savefig(f'dataset/img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "        plt.clf()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(filename,name):\n",
    "    plt.interactive(False)\n",
    "    clip, sample_rate = librosa.load(filename, sr=None)\n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    filename  = 'working/train/' + name + '.jpg'\n",
    "    plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del filename,name,clip,sample_rate,fig,ax,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram_test(filename,name):\n",
    "    plt.interactive(False)\n",
    "    clip, sample_rate = librosa.load(filename, sr=None)\n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    filename  = Path('working/test/' + name + '.jpg')\n",
    "    fig.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del filename,name,clip,sample_rate,fig,ax,S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./dataset/data.csv', 'w', newline='')\n",
    "header = [\"id\",\"class\"]\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "for g in genres:\n",
    "    for filename in os.listdir(f'./dataset/genres/{g}'):\n",
    "        songname = f'./dataset/genres/{g}/{filename}'\n",
    "        create_spectrogram(songname,filename)\n",
    "        \n",
    "        # extracts the  genre name\n",
    "        labels.append(filename.split('.')[0])\n",
    "        ids.append(filename + '.jpg')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'ID': ids, 'Class': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1/255, validation_split=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = df,\n",
    "    directory=\"working/train/\",\n",
    "    x_col = \"ID\",\n",
    "    y_col = \"Class\",\n",
    "    subset=\"training\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(128, 128)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.backend import placeholder\n",
    "from keras.layers import Conv2D, MaxPooling2D, InputLayer\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(128,128,3), name='conv2d_1'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3), name='conv2d_2'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    model.compile(optimizers.rmsprop(lr=0.0005, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fitting keras model, no test gen for now\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "#STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    epochs=75\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SONG_PATH = \"working/train/classical.00000.au.jpg\"\n",
    "STYLE_SONG_PATH = \"working/train/jazz.00000.au.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_HEIGHT = 128\n",
    "TARGET_WIDTH = 128\n",
    "TARGET_SIZE = (TARGET_HEIGHT, TARGET_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cImage = load_img(path=SAMPLE_SONG_PATH, target_size=TARGET_SIZE)\n",
    "cImArr = img_to_array(cImage)\n",
    "cImArr = np.expand_dims(cImArr, axis=0)\n",
    "cImArr = K.variable(cImArr, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cImArr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sImage = load_img(path=SAMPLE_SONG_PATH, target_size=TARGET_SIZE)\n",
    "sImArr = img_to_array(sImage)\n",
    "sImArr = np.expand_dims(sImArr, axis=0)\n",
    "sImArr = K.variable(sImArr, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatedImage = np.random.randint(\n",
    "    256, size=(1, TARGET_WIDTH, TARGET_HEIGHT, 3)).astype('float64')\n",
    "generatedImagePlaceholder = K.placeholder(shape=(1, TARGET_WIDTH, TARGET_HEIGHT, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLayerIndexByName(model, layername):\n",
    "    for idx, layer in enumerate(model.layers):\n",
    "        if layer.name == layername:\n",
    "            return idx\n",
    "        \n",
    "def get_feature_reps(x, layer_names, model):\n",
    "    \"\"\"\n",
    "    Get feature representations of input x for one or more layers in a given model.\n",
    "    \"\"\"\n",
    "    featMatrices = []\n",
    "    inp = model.input\n",
    "    \n",
    "    outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "    functors = [K.function([inp, K.learning_phase()], [out]) for out in outputs]    # evaluation functions\n",
    "\n",
    "    # Testing\n",
    "    layer_outs = [func([x, 1.]) for func in functors]\n",
    "\n",
    "    for ln in layer_names:\n",
    "        i = getLayerIndexByName(model, ln)\n",
    "        featMatrices.append(layer_outs[i])\n",
    "        \n",
    "        \n",
    "    return featMatrices\n",
    "\n",
    "def get_content_loss(F, P):\n",
    "    cLoss = 0.5*K.sum(K.square(F - P))\n",
    "    return cLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Gram_matrix(F):\n",
    "    G = K.dot(F, K.transpose(F))\n",
    "    return G\n",
    "\n",
    "def get_style_loss(ws, Gs, As):\n",
    "    sLoss = K.variable(0.)\n",
    "    for w, G, A in zip(ws, Gs, As):\n",
    "        M_l = K.int_shape(G)[1]\n",
    "        N_l = K.int_shape(G)[0]\n",
    "        G_gram = get_Gram_matrix(G)\n",
    "        A_gram = get_Gram_matrix(A)\n",
    "        sLoss+= w*0.25*K.sum(K.square(G_gram - A_gram))/ (N_l**2 * M_l**2)\n",
    "    return sLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_loss(gImPlaceholder, alpha=1.0, beta=10000.0):\n",
    "    F = get_feature_reps(gImPlaceholder, layer_names=[cLayerName], model=gModel)[0]\n",
    "    Gs = get_feature_reps(gImPlaceholder, layer_names=sLayerNames, model=gModel)\n",
    "    contentLoss = get_content_loss(F, P)\n",
    "    styleLoss = get_style_loss(ws, Gs, As)\n",
    "    totalLoss = alpha*contentLoss + beta*styleLoss\n",
    "    return totalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(gImArr):\n",
    "    \"\"\"\n",
    "    Calculate total loss using K.function\n",
    "    \"\"\"\n",
    "    if gImArr.shape != (1, TARGET_WIDTH, TARGET_WIDTH, 3):\n",
    "        gImArr = gImArr.reshape((1, TARGET_WIDTH, TARGET_HEIGHT, 3))\n",
    "    loss_fcn = K.function([gModel.input], [get_total_loss(gModel.input)])\n",
    "    return loss_fcn([gImArr])[0].astype('float64')\n",
    "\n",
    "def get_grad(gImArr):\n",
    "    \"\"\"\n",
    "    Calculate the gradient of the loss function with respect to the generated image\n",
    "    \"\"\"\n",
    "    if gImArr.shape != (1, TARGET_WIDTH, TARGET_WIDTH, 3):\n",
    "        gImArr = gImArr.reshape((1, TARGET_WIDTH, TARGET_HEIGHT, 3))\n",
    "    grad_fcn = K.function([gModel.input], \n",
    "                          K.gradients(get_total_loss(gModel.input), [gModel.input]))\n",
    "    grad = grad_fcn([gImArr])[0].flatten().astype('float64')\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Style Transfer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf_session = K.get_session()\n",
    "cModel = get_model()\n",
    "sModel = get_model()\n",
    "gModel = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cLayerName = 'conv2d_2'\n",
    "sLayerNames = [\n",
    "    'conv2d_1',\n",
    "    'conv2d_2',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "P = get_feature_reps(x=cImArr, layer_names=[cLayerName], model=cModel)[0]\n",
    "As = get_feature_reps(x=sImArr, layer_names=sLayerNames, model=sModel)\n",
    "ws = np.ones(len(sLayerNames)) / float(len(sLayerNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 4\n",
    "x_val = generatedImage.flatten()\n",
    "xopt, f_val, info= fmin_l_bfgs_b(calculate_loss, x_val, fprime=get_grad,\n",
    "                            maxiter=iterations, disp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xopt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xopt = xopt.reshape(128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.fromarray(xopt, 'RGB')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from scipy.optimize import fmin_l_bfgs_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_session = K.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cModel = VGG16(include_top=False, weights='imagenet', input_tensor=cImArr)\n",
    "sModel = VGG16(include_top=False, weights='imagenet', input_tensor=sImArr)\n",
    "gModel = VGG16(include_top=False, weights='imagenet', input_tensor=generatedImagePlaceholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cLayerName = 'block4_conv2'\n",
    "sLayerNames = [\n",
    "                'block1_conv1',\n",
    "                'block2_conv1',\n",
    "                'block3_conv1',\n",
    "                'block4_conv1',\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = get_feature_reps(x=cImArr, layer_names=[cLayerName], model=cModel)[0]\n",
    "As = get_feature_reps(x=sImArr, layer_names=sLayerNames, model=sModel)\n",
    "ws = np.ones(len(sLayerNames))/float(len(sLayerNames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterations = 4\n",
    "x_val = generatedImage.flatten()\n",
    "xopt, f_val, info= fmin_l_bfgs_b(calculate_loss, x_val, fprime=get_grad,\n",
    "                            maxiter=iterations, disp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xopt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xopt = xopt.reshape(128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.fromarray(xopt, 'RGB')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
