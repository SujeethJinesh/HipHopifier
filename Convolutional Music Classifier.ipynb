{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "import gc\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = plt.get_cmap('inferno')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "genres = 'classical jazz metal pop rock'.split()\n",
    "for g in genres:\n",
    "    pathlib.Path(f'dataset/img_data/{g}').mkdir(parents=True, exist_ok=True)     \n",
    "    for filename in os.listdir(f'./dataset/genres/{g}'):\n",
    "        songname = f'./dataset/genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        plt.savefig(f'dataset/img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "        plt.clf()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(filename,name):\n",
    "    plt.interactive(False)\n",
    "    clip, sample_rate = librosa.load(filename, sr=None)\n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    filename  = 'working/train/' + name + '.jpg'\n",
    "    plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del filename,name,clip,sample_rate,fig,ax,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram_test(filename,name):\n",
    "    plt.interactive(False)\n",
    "    clip, sample_rate = librosa.load(filename, sr=None)\n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    filename  = Path('working/test/' + name + '.jpg')\n",
    "    fig.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del filename,name,clip,sample_rate,fig,ax,S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./dataset/data.csv', 'w', newline='')\n",
    "header = [\"id\",\"class\"]\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "for g in genres:\n",
    "    for filename in os.listdir(f'./dataset/genres/{g}'):\n",
    "        songname = f'./dataset/genres/{g}/{filename}'\n",
    "        create_spectrogram(songname,filename)\n",
    "        \n",
    "        # extracts the  genre name\n",
    "        labels.append(filename.split('.')[0])\n",
    "        ids.append(filename + '.jpg')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'ID': ids, 'Class': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classical.00004.au.jpg</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classical.00001.au.jpg</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>classical.00002.au.jpg</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>classical.00003.au.jpg</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>classical.00008.au.jpg</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID      Class\n",
       "0  classical.00004.au.jpg  classical\n",
       "1  classical.00001.au.jpg  classical\n",
       "2  classical.00002.au.jpg  classical\n",
       "3  classical.00003.au.jpg  classical\n",
       "4  classical.00008.au.jpg  classical"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1/255, validation_split=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = df,\n",
    "    directory=\"working/train/\",\n",
    "    x_col = \"ID\",\n",
    "    y_col = \"Class\",\n",
    "    subset=\"training\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(64, 64)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jeremy/anaconda3/envs/cs4803-project/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/jeremy/anaconda3/envs/cs4803-project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 62, 62, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 31, 31, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 29, 29, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 2,677,061\n",
      "Trainable params: 2,677,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(64,64,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizers.rmsprop(lr=0.0005, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jeremy/anaconda3/envs/cs4803-project/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6071 - acc: 0.3125\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 4.5988 - acc: 0.1667\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 1s 892ms/step - loss: 1.5730 - acc: 0.2812\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.5907 - acc: 0.1667\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 1.4935 - acc: 0.2812\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.3805 - acc: 0.3333\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 1s 888ms/step - loss: 1.4234 - acc: 0.2500\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.6450 - acc: 0.0000e+00\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 1s 874ms/step - loss: 1.4621 - acc: 0.2188\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.5757 - acc: 0.1667\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 1s 906ms/step - loss: 1.3968 - acc: 0.3438\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 1.3478 - acc: 0.5000\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 1.3353 - acc: 0.2500\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.6225 - acc: 0.3333\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 1s 902ms/step - loss: 1.4337 - acc: 0.2188\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.3316 - acc: 0.3333\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 1.2916 - acc: 0.3438\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.5302 - acc: 0.1667\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 1s 893ms/step - loss: 1.3076 - acc: 0.2812\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1.6841 - acc: 0.0000e+00\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.7255 - acc: 0.2188\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.4323 - acc: 0.3333\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3960 - acc: 0.4375\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 1.2911 - acc: 0.6667\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 1s 927ms/step - loss: 1.3224 - acc: 0.2500\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 1.1502 - acc: 0.6667\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 1s 929ms/step - loss: 1.3543 - acc: 0.3125\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.1694 - acc: 0.5000\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 1s 929ms/step - loss: 1.3090 - acc: 0.4375\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 1.6860 - acc: 0.1667\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 1s 997ms/step - loss: 1.3771 - acc: 0.3125\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 1.2246 - acc: 0.6667\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 1s 902ms/step - loss: 1.2055 - acc: 0.5000\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9933 - acc: 0.8333\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 1.0472 - acc: 0.6250\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0356 - acc: 0.1667\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 1s 936ms/step - loss: 1.2558 - acc: 0.3438\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.1557 - acc: 0.5000\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 1.0570 - acc: 0.5312\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9584 - acc: 0.8333\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 1s 871ms/step - loss: 0.8745 - acc: 0.6562\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8052 - acc: 0.6667\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 1.0289 - acc: 0.4688\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 2.5099 - acc: 0.3333\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 1s 870ms/step - loss: 1.1684 - acc: 0.4375\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.3797 - acc: 0.6667\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 1s 938ms/step - loss: 0.9944 - acc: 0.5938\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.0830 - acc: 0.6667\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 1s 954ms/step - loss: 0.8487 - acc: 0.7188\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.0669 - acc: 0.5000\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9730 - acc: 0.5312\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5767 - acc: 0.6667\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7035 - acc: 0.6875\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 1.0320 - acc: 0.6667\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 1s 892ms/step - loss: 0.7617 - acc: 0.5625\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.9978 - acc: 0.5000\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7470 - acc: 0.1875\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 1.4861 - acc: 0.1667\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0467 - acc: 0.5312\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 1.0392 - acc: 0.3333\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8071 - acc: 0.6875\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7040 - acc: 0.8333\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 1s 974ms/step - loss: 0.6672 - acc: 0.7812\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9944 - acc: 0.6667\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 0.5451 - acc: 0.7812\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.5942 - acc: 0.6667\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.7894 - acc: 0.6875\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1315 - acc: 1.0000\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 1s 920ms/step - loss: 0.7180 - acc: 0.6250\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.5864 - acc: 0.6667\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 1s 912ms/step - loss: 0.7538 - acc: 0.6562\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.1140 - acc: 0.3333\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.6965 - acc: 0.6250\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.3536 - acc: 0.8333\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 1s 871ms/step - loss: 0.7980 - acc: 0.6562\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.5260 - acc: 0.8333\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 1s 922ms/step - loss: 0.5360 - acc: 0.7500\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.7348 - acc: 0.6667\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 0.4942 - acc: 0.8125\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.5155 - acc: 0.8333\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 1s 938ms/step - loss: 1.2855 - acc: 0.6250\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.1699 - acc: 0.3333\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.5206 - acc: 0.8125\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6384 - acc: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/150\n",
      "1/1 [==============================] - 1s 914ms/step - loss: 0.6977 - acc: 0.6562\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1667 - acc: 1.0000\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 0.5164 - acc: 0.7500\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.8197 - acc: 0.8333\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 1s 905ms/step - loss: 1.3388 - acc: 0.5938\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8299 - acc: 0.5000\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6110 - acc: 0.7500\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.4446 - acc: 0.8333\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5886 - acc: 0.7500\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.5924 - acc: 0.8333\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4915 - acc: 0.7812\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.6389 - acc: 0.6667\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7000 - acc: 0.6875\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.3415 - acc: 0.8333\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4330 - acc: 0.8125\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.2133 - acc: 1.0000\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2364 - acc: 0.9062\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.6535 - acc: 0.6667\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9229 - acc: 0.6875\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.9542 - acc: 0.6667\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6237 - acc: 0.7500\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.3709 - acc: 0.8333\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4389 - acc: 0.8125\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 1.1465 - acc: 0.3333\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4429 - acc: 0.8750\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 1.1697 - acc: 0.5000\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0000 - acc: 0.5625\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5604 - acc: 0.8333\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7054 - acc: 0.6875\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.9855 - acc: 0.5000\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5089 - acc: 0.8438\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.3674 - acc: 0.6667\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3932 - acc: 0.8438\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.7036 - acc: 0.6667\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1267 - acc: 0.6562\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.8553 - acc: 0.5000\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5795 - acc: 0.7500\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.3397 - acc: 0.8333\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4484 - acc: 0.7812\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.6407 - acc: 0.8333\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3852 - acc: 0.8125\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.3407 - acc: 0.8333\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3994 - acc: 0.8125\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.4767 - acc: 0.6667\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3284 - acc: 0.8750\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.2468 - acc: 1.0000\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3879 - acc: 0.8125\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.7072 - acc: 0.6667\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.0307 - acc: 0.5938\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.4888 - acc: 0.6667\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3507 - acc: 0.9062\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.3439 - acc: 0.8333\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3634 - acc: 0.8125\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.2394 - acc: 1.0000\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4092 - acc: 0.8125\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.2093 - acc: 0.8333\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3790 - acc: 0.7188\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.3528 - acc: 0.8333\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2407 - acc: 0.9062\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.1566 - acc: 1.0000\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5294 - acc: 0.8438\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.9005 - acc: 0.6667\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3848 - acc: 0.6875\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.3562 - acc: 1.0000\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2817 - acc: 0.9062\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.4909 - acc: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feef94ca860>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting keras model, no test gen for now\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "#STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    epochs=150\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SONG_PATH = \"working/train/classical.00000.au.jpg\"\n",
    "STYLE_SONG_PATH = \"working/train/jazz.00000.au.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_HEIGHT = 217\n",
    "TARGET_WIDTH = 223\n",
    "TARGET_SIZE = (TARGET_HEIGHT, TARGET_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cImage = load_img(path=SAMPLE_SONG_PATH, target_size=TARGET_SIZE)\n",
    "cImArr = img_to_array(cImage)\n",
    "cImArr = K.variable(cImArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sImage = load_img(path=SAMPLE_SONG_PATH, target_size=TARGET_SIZE)\n",
    "sImArr = img_to_array(sImage)\n",
    "sImArr = K.variable(cImArr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
