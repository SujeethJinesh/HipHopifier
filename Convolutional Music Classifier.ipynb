{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-b78f0098274b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'path'"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "import gc\n",
    "from path import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = plt.get_cmap('inferno')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "genres = 'classical jazz metal pop rock'.split()\n",
    "for g in genres:\n",
    "    pathlib.Path(f'dataset/img_data/{g}').mkdir(parents=True, exist_ok=True)     \n",
    "    for filename in os.listdir(f'./dataset/genres/{g}'):\n",
    "        songname = f'./dataset/genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        plt.savefig(f'dataset/img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "        plt.clf()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(filename,name):\n",
    "    plt.interactive(False)\n",
    "    clip, sample_rate = librosa.load(filename, sr=None)\n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    filename  = 'working/train/' + name + '.jpg'\n",
    "    plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del filename,name,clip,sample_rate,fig,ax,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram_test(filename,name):\n",
    "    plt.interactive(False)\n",
    "    clip, sample_rate = librosa.load(filename, sr=None)\n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    filename  = Path('working/test/' + name + '.jpg')\n",
    "    fig.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del filename,name,clip,sample_rate,fig,ax,S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./dataset/data.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "for g in genres:\n",
    "    for filename in os.listdir(f'./dataset/genres/{g}'):\n",
    "        songname = f'./dataset/genres/{g}/{filename}'\n",
    "        create_spectrogram(songname,filename)\n",
    "        \n",
    "        # extracts the  genre name\n",
    "        labels.append(filename.split('.')[0])\n",
    "        ids.append(filename + '.jpg')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'ID': ids, 'Class': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classical.00004.au.jpg</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classical.00001.au.jpg</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>classical.00002.au.jpg</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>classical.00003.au.jpg</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>classical.00008.au.jpg</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID      Class\n",
       "0  classical.00004.au.jpg  classical\n",
       "1  classical.00001.au.jpg  classical\n",
       "2  classical.00002.au.jpg  classical\n",
       "3  classical.00003.au.jpg  classical\n",
       "4  classical.00008.au.jpg  classical"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1/255, validation_split=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = df,\n",
    "    directory=\"working/train/\",\n",
    "    x_col = \"ID\",\n",
    "    y_col = \"Class\",\n",
    "    subset=\"training\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(64, 64)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 62, 62, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 31, 31, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 29, 29, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 2,677,061\n",
      "Trainable params: 2,677,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(64,64,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizers.rmsprop(lr=0.0005, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.6342 - acc: 0.0938\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.6663 - acc: 0.0000e+00\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 1s 874ms/step - loss: 1.5291 - acc: 0.2500\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.5017 - acc: 0.1667\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 1.4587 - acc: 0.2500\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.5404 - acc: 0.1667\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 1s 904ms/step - loss: 1.4587 - acc: 0.1562\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.4835 - acc: 0.1667\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 1.4340 - acc: 0.3125\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.4008 - acc: 0.1667\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 1.3374 - acc: 0.3438\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.6373 - acc: 0.3333\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 1s 919ms/step - loss: 1.3910 - acc: 0.3750\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.4821 - acc: 0.0000e+00\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 1s 925ms/step - loss: 1.4273 - acc: 0.2812\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1.3405 - acc: 0.5000\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 1.4105 - acc: 0.2500\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.6100 - acc: 0.1667\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4685 - acc: 0.2188\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 1.3166 - acc: 0.5000\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 1.4629 - acc: 0.2500\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 1.4002 - acc: 0.1667\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 1s 920ms/step - loss: 1.4012 - acc: 0.2500\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.3274 - acc: 0.1667\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 1.5417 - acc: 0.2812\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 1.3567 - acc: 0.5000\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 1s 941ms/step - loss: 1.4100 - acc: 0.1875\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 1.2937 - acc: 0.1667\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 1.4564 - acc: 0.2188\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.0979 - acc: 0.8333\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 1s 926ms/step - loss: 1.3232 - acc: 0.3750\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 1.2111 - acc: 0.5000\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 1s 989ms/step - loss: 1.2380 - acc: 0.3438\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.7167 - acc: 0.1667\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 1.3814 - acc: 0.2812\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 1.3069 - acc: 0.1667\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 1s 920ms/step - loss: 1.2901 - acc: 0.2812\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 1.3878 - acc: 0.1667\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 1s 986ms/step - loss: 1.2137 - acc: 0.5625\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 1.0183 - acc: 0.6667\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 1.0232 - acc: 0.6250\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.0429 - acc: 0.5000\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 1s 978ms/step - loss: 1.7597 - acc: 0.2500\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.6071 - acc: 0.0000e+00\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 1s 913ms/step - loss: 1.2497 - acc: 0.4688\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 1.3232 - acc: 0.3333\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1350 - acc: 0.5938\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.2277 - acc: 0.3333\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0834 - acc: 0.4688\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7671 - acc: 0.8333\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7551 - acc: 0.6875\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9665 - acc: 0.5000\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 1s 979ms/step - loss: 1.3152 - acc: 0.4688\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 3.7913 - acc: 0.0000e+00\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1117 - acc: 0.4375\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 1.1197 - acc: 0.5000\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0982 - acc: 0.4375\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.9288 - acc: 0.5000\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8387 - acc: 0.6875\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.6994 - acc: 0.8333\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7262 - acc: 0.7188\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.8748 - acc: 0.3333\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7745 - acc: 0.6875\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 1.2607 - acc: 0.3333\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8635 - acc: 0.6875\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.4708 - acc: 0.6667\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8526 - acc: 0.5625\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.5644 - acc: 0.8333\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6544 - acc: 0.7188\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 1.3837 - acc: 0.5000\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8092 - acc: 0.7188\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.3954 - acc: 0.8333\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7255 - acc: 0.7500\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.6233 - acc: 0.6667\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8340 - acc: 0.6875\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.5934 - acc: 0.6667\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6986 - acc: 0.7500\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.4800 - acc: 0.6667\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6538 - acc: 0.8125\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.1672 - acc: 1.0000\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5407 - acc: 0.7188\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.8937 - acc: 0.6667\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.8033 - acc: 0.4375\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.6737 - acc: 0.5000\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5741 - acc: 0.7812\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.5728 - acc: 0.8333\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6164 - acc: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.2149 - acc: 0.8333\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6710 - acc: 0.7188\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.2655 - acc: 1.0000\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 1s 986ms/step - loss: 0.5763 - acc: 0.7500\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9190 - acc: 0.3333\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1462 - acc: 0.4062\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.5325 - acc: 0.8333\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 1s 996ms/step - loss: 0.6453 - acc: 0.7812\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.3611 - acc: 0.8333\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.5018 - acc: 0.8438\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.4111 - acc: 0.8333\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.7918 - acc: 0.7188\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 1.3563 - acc: 0.3333\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.6998 - acc: 0.6875\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5011 - acc: 0.8333\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5026 - acc: 0.8125\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.4701 - acc: 0.8333\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4287 - acc: 0.8438\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.7739 - acc: 0.6667\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7785 - acc: 0.7500\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.4370 - acc: 0.8333\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 1s 937ms/step - loss: 0.4363 - acc: 0.8438\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.4781 - acc: 0.8333\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7849 - acc: 0.6875\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6527 - acc: 0.6667\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1437 - acc: 0.5938\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8485 - acc: 0.6667\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 1s 929ms/step - loss: 0.4549 - acc: 0.7812\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6052 - acc: 0.6667\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1897 - acc: 0.5625\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.5025 - acc: 0.6667\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5018 - acc: 0.8125\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.3357 - acc: 0.8333\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.4552 - acc: 0.7500\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5527 - acc: 0.6667\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4263 - acc: 0.8438\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.2602 - acc: 1.0000\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 1s 918ms/step - loss: 0.2776 - acc: 0.9062\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.4413 - acc: 0.8333\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7091 - acc: 0.6562\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 1.4296 - acc: 0.5000\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 1s 980ms/step - loss: 0.9723 - acc: 0.5625\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.6613 - acc: 0.8333\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 1s 913ms/step - loss: 0.4562 - acc: 0.7500\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3886 - acc: 0.8333\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.4170 - acc: 0.8750\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3818 - acc: 0.8333\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 1s 892ms/step - loss: 0.4234 - acc: 0.7812\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.2338 - acc: 0.8333\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 1s 922ms/step - loss: 0.2790 - acc: 0.8438\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3221 - acc: 0.8333\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 0.2810 - acc: 0.9062\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3329 - acc: 0.8333\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 1s 901ms/step - loss: 0.3589 - acc: 0.8438\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.1855 - acc: 1.0000\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 1s 874ms/step - loss: 0.7261 - acc: 0.7188\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.1240 - acc: 0.6667\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.8682 - acc: 0.6562\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.3674 - acc: 1.0000\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3450 - acc: 0.8125\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.2043 - acc: 1.0000\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3622 - acc: 0.7812\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.6010 - acc: 0.8333\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'valid_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-6388b8e2b3f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0;31m model.evaluate_generator(generator=valid_generator, steps=STEP_SIZE_VALID\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_generator' is not defined"
     ]
    }
   ],
   "source": [
    "#Fitting keras model, no test gen for now\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "#STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    epochs=150\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
